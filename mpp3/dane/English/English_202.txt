[97] In 2016, Microsoft tested a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.

[98] Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.

[99] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who reminds engineers that "There’s nothing artificial about AI...It’s inspired by people, it’s created by people, and—most importantly—it impacts people.

It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.”[100] Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set.

In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model.